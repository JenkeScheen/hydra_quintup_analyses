{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation of t-SNE overlap approach\n",
    "Make t-SNE of all freesolv quintuplicates. Make a split such that the test quints are not well-represented in the training set. Check if these are poorly predicted on by a model. Then incrementally add back the most un-represented cases and update statistics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import csv\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "plot_kwds = {'alpha' : 0.5, 's' : 80, 'linewidths':0}\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import sklearn\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import metrics\n",
    "from scipy import stats\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import Draw, rdFMCS, AllChem, rdmolfiles, Descriptors, rdchem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>set</th>\n",
       "      <th>pertname</th>\n",
       "      <th>pertsmarts</th>\n",
       "      <th>num_ha</th>\n",
       "      <th>sem</th>\n",
       "      <th>1</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>8</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TrainingSet</td>\n",
       "      <td>mobley_1662128~mobley_7047032</td>\n",
       "      <td>[C*]C~[C*]C.[C*]Cl</td>\n",
       "      <td>2</td>\n",
       "      <td>0.156846</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2173</td>\n",
       "      <td>5.0240</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>-0.222222</td>\n",
       "      <td>33.961028</td>\n",
       "      <td>2.425788</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TrainingSet</td>\n",
       "      <td>mobley_7047032~mobley_1662128</td>\n",
       "      <td>[C*]C.[C*]Cl~[C*]C</td>\n",
       "      <td>2</td>\n",
       "      <td>0.156846</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2173</td>\n",
       "      <td>-5.0240</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>-33.961028</td>\n",
       "      <td>-2.425788</td>\n",
       "      <td>-6</td>\n",
       "      <td>1</td>\n",
       "      <td>-10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TrainingSet</td>\n",
       "      <td>mobley_7015518~mobley_303222</td>\n",
       "      <td>[C*]OC~[C*]CC</td>\n",
       "      <td>1</td>\n",
       "      <td>0.108653</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1537</td>\n",
       "      <td>3.0320</td>\n",
       "      <td>-9.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.979265</td>\n",
       "      <td>-1.110072</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TrainingSet</td>\n",
       "      <td>mobley_303222~mobley_7015518</td>\n",
       "      <td>[C*]CC~[C*]OC</td>\n",
       "      <td>1</td>\n",
       "      <td>0.108653</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.1537</td>\n",
       "      <td>-3.0320</td>\n",
       "      <td>9.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.979265</td>\n",
       "      <td>1.110072</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TrainingSet</td>\n",
       "      <td>mobley_1046331~mobley_3515580</td>\n",
       "      <td>[C*]O~[C*]O</td>\n",
       "      <td>1</td>\n",
       "      <td>0.113167</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3492</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5365</th>\n",
       "      <td>TrainingSet</td>\n",
       "      <td>mobley_5326154~mobley_1019269</td>\n",
       "      <td>[C*]N(C)C1CCCCC1~[C*]CCCO</td>\n",
       "      <td>8</td>\n",
       "      <td>0.155166</td>\n",
       "      <td>-1</td>\n",
       "      <td>-11</td>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "      <td>-4</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.1019</td>\n",
       "      <td>-18.5662</td>\n",
       "      <td>16.99</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-53.062935</td>\n",
       "      <td>0.048361</td>\n",
       "      <td>-68</td>\n",
       "      <td>-7</td>\n",
       "      <td>-26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5366</th>\n",
       "      <td>TrainingSet</td>\n",
       "      <td>mobley_1019269~mobley_7774695</td>\n",
       "      <td>[C*]CCCO~[C*]NC1CCCCC1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.119793</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7597</td>\n",
       "      <td>13.9389</td>\n",
       "      <td>-8.20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>39.047285</td>\n",
       "      <td>-0.019931</td>\n",
       "      <td>44</td>\n",
       "      <td>5</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5367</th>\n",
       "      <td>TrainingSet</td>\n",
       "      <td>mobley_7774695~mobley_1019269</td>\n",
       "      <td>[C*]NC1CCCCC1~[C*]CCCO</td>\n",
       "      <td>7</td>\n",
       "      <td>0.119793</td>\n",
       "      <td>-1</td>\n",
       "      <td>-8</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7597</td>\n",
       "      <td>-13.9389</td>\n",
       "      <td>8.20</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.222222</td>\n",
       "      <td>-39.047285</td>\n",
       "      <td>0.019931</td>\n",
       "      <td>-44</td>\n",
       "      <td>-5</td>\n",
       "      <td>-20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5368</th>\n",
       "      <td>TrainingSet</td>\n",
       "      <td>mobley_1019269~mobley_1189457</td>\n",
       "      <td>[C*]CCCO~[C*]SC1CCCCC1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.281720</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.9033</td>\n",
       "      <td>18.3942</td>\n",
       "      <td>5.07</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>56.008457</td>\n",
       "      <td>0.974590</td>\n",
       "      <td>44</td>\n",
       "      <td>5</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5369</th>\n",
       "      <td>TrainingSet</td>\n",
       "      <td>mobley_1189457~mobley_1019269</td>\n",
       "      <td>[C*]SC1CCCCC1~[C*]CCCO</td>\n",
       "      <td>7</td>\n",
       "      <td>0.281720</td>\n",
       "      <td>0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.9033</td>\n",
       "      <td>-18.3942</td>\n",
       "      <td>-5.07</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.222222</td>\n",
       "      <td>-56.008457</td>\n",
       "      <td>-0.974590</td>\n",
       "      <td>-44</td>\n",
       "      <td>-5</td>\n",
       "      <td>-20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3567 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              set                       pertname                 pertsmarts  \\\n",
       "0     TrainingSet  mobley_1662128~mobley_7047032         [C*]C~[C*]C.[C*]Cl   \n",
       "1     TrainingSet  mobley_7047032~mobley_1662128         [C*]C.[C*]Cl~[C*]C   \n",
       "2     TrainingSet   mobley_7015518~mobley_303222              [C*]OC~[C*]CC   \n",
       "3     TrainingSet   mobley_303222~mobley_7015518              [C*]CC~[C*]OC   \n",
       "4     TrainingSet  mobley_1046331~mobley_3515580                [C*]O~[C*]O   \n",
       "...           ...                            ...                        ...   \n",
       "5365  TrainingSet  mobley_5326154~mobley_1019269  [C*]N(C)C1CCCCC1~[C*]CCCO   \n",
       "5366  TrainingSet  mobley_1019269~mobley_7774695     [C*]CCCO~[C*]NC1CCCCC1   \n",
       "5367  TrainingSet  mobley_7774695~mobley_1019269     [C*]NC1CCCCC1~[C*]CCCO   \n",
       "5368  TrainingSet  mobley_1019269~mobley_1189457     [C*]CCCO~[C*]SC1CCCCC1   \n",
       "5369  TrainingSet  mobley_1189457~mobley_1019269     [C*]SC1CCCCC1~[C*]CCCO   \n",
       "\n",
       "      num_ha       sem  1   4  5  8  10  ...      71       72     73   74  \\\n",
       "0          2  0.156846  0   0  1  1   0  ...  0.2173   5.0240   0.00  2.5   \n",
       "1          2  0.156846  0   0 -1 -1   0  ... -0.2173  -5.0240   0.00 -2.5   \n",
       "2          1  0.108653  0   2  0 -1   1  ...  1.1537   3.0320  -9.23  0.0   \n",
       "3          1  0.108653  0  -2  0  1  -1  ... -1.1537  -3.0320   9.23  0.0   \n",
       "4          1  0.113167  0   0  0  0   0  ... -0.3492   0.2280   0.00  0.5   \n",
       "...      ...       ... ..  .. .. ..  ..  ...     ...      ...    ...  ...   \n",
       "5365       8  0.155166 -1 -11 -4  0  -4  ... -1.1019 -18.5662  16.99 -1.0   \n",
       "5366       7  0.119793  1   8  3  0   3  ...  0.7597  13.9389  -8.20  0.5   \n",
       "5367       7  0.119793 -1  -8 -3  0  -3  ... -0.7597 -13.9389   8.20 -0.5   \n",
       "5368       7  0.281720  0   7  3  0   3  ...  1.9033  18.3942   5.07  0.5   \n",
       "5369       7  0.281720  0  -7 -3  0  -3  ... -1.9033 -18.3942  -5.07 -0.5   \n",
       "\n",
       "            75         77        78  79  80    81  \n",
       "0    -0.222222  33.961028  2.425788   6  -1  10.0  \n",
       "1     0.222222 -33.961028 -2.425788  -6   1 -10.0  \n",
       "2     0.000000  -1.979265 -1.110072   0   0   0.0  \n",
       "3     0.000000   1.979265  1.110072   0   0   0.0  \n",
       "4     0.666667   0.000000  0.000000  -8   2   2.0  \n",
       "...        ...        ...       ...  ..  ..   ...  \n",
       "5365 -0.666667 -53.062935  0.048361 -68  -7 -26.0  \n",
       "5366  0.222222  39.047285 -0.019931  44   5  20.0  \n",
       "5367 -0.222222 -39.047285  0.019931 -44  -5 -20.0  \n",
       "5368  0.222222  56.008457  0.974590  44   5  20.0  \n",
       "5369 -0.222222 -56.008457 -0.974590 -44  -5 -20.0  \n",
       "\n",
       "[3567 rows x 52 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quints_fps = pd.read_csv(\"output/quints_fps.csv\", header=None)\n",
    "quints_infos = pd.read_csv(\"output/quints_infos.csv\", names=[\"set\", \"pertname\", \"pertsmarts\", \"num_ha\", \"sem\"])\n",
    "\n",
    "quints_whole_df = pd.concat([quints_infos, quints_fps], axis=1)\n",
    "\n",
    "# drop NaN columns (happens with molprop generation where (error) strings can't be subtracted)\n",
    "quints_whole_df = quints_whole_df.dropna(axis=1)\n",
    "\n",
    "# drop rows where SEM == 0.0. It seems some very large perturbations get this value too, so makes training noisy.\n",
    "quints_whole_df = quints_whole_df[quints_whole_df[\"sem\"] > 0.0001]\n",
    "\n",
    "# drop columns where all values are 0.\n",
    "quints_whole_df = quints_whole_df.loc[:, (quints_whole_df != 0).any(axis=0)]\n",
    "\n",
    "# TMP DROP DUPLICATES --> should be fewer duplicates when we move up to more features.\n",
    "quints_whole_df = quints_whole_df.drop_duplicates(subset=quints_whole_df.columns.difference(['sem','set','pertname','pertsmarts']))\n",
    "\n",
    "quints_whole_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretize SEM label into categorical bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bin, Min, Max, Volume\n",
      "0 0.01 0.05 357\n",
      "1 0.05 0.07 358\n",
      "2 0.07 0.1 356\n",
      "3 0.1 0.12 356\n",
      "4 0.12 0.15 358\n",
      "5 0.15 0.19 356\n",
      "6 0.19 0.26 356\n",
      "7 0.26 0.49 356\n",
      "8 0.49 1.47 358\n",
      "9 1.47 97.24 356\n"
     ]
    }
   ],
   "source": [
    "### TMP DISCRETIZE BY STRATIFICATION:\n",
    "n_bins=10\n",
    "\n",
    "binned_sem = pd.qcut(quints_whole_df[\"sem\"], n_bins, labels=False)\n",
    "bin_means = []\n",
    "quints_whole_df[\"sem_bin\"] = binned_sem\n",
    "print(\"Bin, Min, Max, Volume\")\n",
    "for n_bin, df_group in quints_whole_df.groupby(by=\"sem_bin\"):\n",
    "    print(n_bin, round(min(df_group[\"sem\"].values), 2), round(max(df_group[\"sem\"].values), 2), len(df_group))\n",
    "    bin_means.append(np.mean(df_group[\"sem\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "quints_fps = quints_whole_df.drop([\"set\", \"pertname\", \"pertsmarts\", \"num_ha\", \"sem\", \"sem_bin\"], axis=1)\n",
    "quints_fps = quints_fps.values\n",
    "quints_infos = quints_whole_df[[\"set\", \"pertname\", \"pertsmarts\", \"num_ha\", \"sem\", \"sem_bin\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train (orange) and test (blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def takeSubset(indices, quints_whole_df):\n",
    "    \"\"\"Take a selection of a dataframe using indices\"\"\"\n",
    "    subset = quints_whole_df.iloc[indices]\n",
    "    \n",
    "    return subset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def takeInfo(perts_df):\n",
    "    \"\"\"from the input dataframe, return arrays of fingerprints and SEMs\"\"\"\n",
    "    sems = perts_df[[\"sem_bin\", \"sem\"]].values\n",
    "    \n",
    "    # fps is a bit more involved. Remove everything but the FP columns, return as 2d array.\n",
    "    fps_df = perts_df.drop([\"set\", \"pertname\", \"pertsmarts\", \"num_ha\", \"sem\", \"sem_bin\"], axis=1)\n",
    "    fps = fps_df.values\n",
    "\n",
    "    return fps, sems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessSets(test1, test2, train):\n",
    "    \"\"\"standardises and reduces dimensionality to 95% VE; returns arrays\"\"\"\n",
    "    \n",
    "    #### fit the scaler on training set.\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    train_scaled = scaler.fit_transform(train)\n",
    "    \n",
    "    # transform both the training set and the test sets.\n",
    "    test1_scaled = scaler.transform(test1)\n",
    "    test2_scaled = scaler.transform(test2)\n",
    "    \n",
    "    #### fit PCA on training set with 95% variance explained.\n",
    "    pca = PCA(n_components=0.95)\n",
    "    train_preprocessed = pca.fit_transform(train_scaled)\n",
    "    \n",
    "    # transform both the training set and the test sets.\n",
    "    test1_preprocessed = pca.transform(test1_scaled)\n",
    "    test2_preprocessed = pca.transform(test2_scaled)\n",
    "    \n",
    "    return test1_preprocessed, test2_preprocessed, train_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TMP RANDOM SPLIT INSTEAD OF TSNE SPLIT\n",
    "from sklearn.model_selection import train_test_split\n",
    "whole_set, whole_set_sem_bins = takeInfo(takeSubset(np.array(range(len(quints_whole_df))), quints_whole_df))\n",
    "\n",
    "train_set, test_set1, train_sems, upper_test_sems = train_test_split(whole_set, whole_set_sem_bins, test_size=0.2, random_state=42)\n",
    "\n",
    "# adjust label arrays such that we train on classes, but eep the actual SEM values for later.\n",
    "train_sems_values = train_sems[:,1]\n",
    "train_sems = train_sems[:,0]\n",
    "\n",
    "upper_test_sems_values = upper_test_sems[:,1]\n",
    "upper_test_sems = upper_test_sems[:,0]\n",
    "\n",
    "n_classes = len(set(train_sems))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be8d9d487b0b4f1c847404457c4cb4bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "grid_predictions = np.empty((len(test_set1),n_classes))\n",
    "\n",
    "for i in tqdm(range(15)):                            \n",
    "    forest = RandomForestClassifier(random_state = 1)\n",
    "\n",
    "    n_estimators = [100, 300, 500, 800, 1200]\n",
    "    max_depth = [5, 8, 15, 25, 30, 50]\n",
    "    min_samples_split = [2, 5, 10, 15, 100]\n",
    "    min_samples_leaf = [1, 2, 5, 10] \n",
    "\n",
    "    hyperF = dict(n_estimators = n_estimators, max_depth = max_depth,  \n",
    "                  min_samples_split = min_samples_split, \n",
    "                 min_samples_leaf = min_samples_leaf)\n",
    "\n",
    "    gridF = RandomizedSearchCV(forest, hyperF, cv = 5, n_iter=50, verbose = 0, \n",
    "                          n_jobs = -1)\n",
    "    bestF = gridF.fit(np.array(train_set), np.array(train_sems))\n",
    "\n",
    "    predicted_probas = gridF.best_estimator_.predict_proba(test_set1) \n",
    "    grid_predictions += predicted_probas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.96801061 1.17062468 1.94932262 ... 0.4874873  1.3690186  1.16131963]\n",
      " [0.57384288 1.88299317 0.85634773 ... 1.63634524 4.22314636 0.98776268]\n",
      " [0.48887449 1.02600217 1.75130489 ... 1.73596163 5.51161382 1.15311694]\n",
      " ...\n",
      " [4.28991602 1.85002048 2.04313152 ... 0.7833922  0.30148887 0.39307762]\n",
      " [2.31426453 1.11549703 1.76583567 ... 1.03186111 1.74338187 1.23934574]\n",
      " [1.08630746 1.98034514 1.43055496 ... 1.8191541  0.74580002 2.30006743]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2974901887383297"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(grid_predictions)\n",
    "model_preds = [np.argmax(pred) for pred in grid_predictions]\n",
    "stats.kendalltau(upper_test_sems, model_preds)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22214773004257618"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.balanced_accuracy_score(upper_test_sems, model_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
